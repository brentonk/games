%% need no \usepackage{Sweave.sty}
\documentclass[article]{jss}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{subfig}
\usepackage{todonotes}
\usepackage{multirow}

\author{Brenton Kenkel\\University of Rochester \And
  Curtis S. Signorino\\University of Rochester}
\Plainauthor{Brenton Kenkel, Curtis S. Signorino}

\title{Estimating Models of Strategic Interaction in \proglang{R}}
\Plaintitle{Estimating Models of Strategic Interaction in R}

\Abstract{%
  This article introduces new software, the \pkg{games} package, for the
  estimation of strategic statistical models in \proglang{R}.  In these models,
  the probability distribution over outcomes corresponds to the equilibrium of
  an underlying game form.  We review such models and provide derivations for
  one example, including discussion of alternative motivations for the
  stochastic component of the models.  We introduce the basic functionality of
  the \pkg{games} package, such as how to estimate players' utilities for
  outcomes as a function of covariates.  The package implements maximum
  likelihood estimation for the most commonly used models of strategic choice,
  including three extensive form games and an ultimatum bargaining model.  The
  software also includes functions for bootstrapping, plotting fitted values
  with their confidence intervals, performing non-nested model comparisons, and
  checking global convergence failures.  We use the new software to replicate
  \citeauthor{Leblang2003}'s \citeyearpar{Leblang2003} analysis of speculative
  currency attacks.
%
}

\Keywords{random utility models, structural estimation, game theory,
  econometrics, political science}

\Address{
  Brenton Kenkel\\
  315A Harkness Hall\\
  Department of Political Science\\
  University of Rochester\\
  Rochester, NY 14627\\
  Email: \email{brenton.kenkel@gmail.com}\\
  
  Curtis S. Signorino\\
  303 Harkness Hall\\
  Department of Political Science\\
  University of Rochester\\
  Rochester, NY 14627\\
  Email: \email{curt.signorino@rochester.edu}
}

\begin{document}

\maketitle

<<setup,echo=false,results=hide>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
@ 

\section{Introduction}

The \pkg{games} package provides functions for estimation of statistical models
of strategic interaction in the \proglang{R} language \citep{Rlang}.  These are
random-utility models of choices by multiple agents, each of whom conditions his
or her actions on the likely decisions of the other players.  In these models,
the distribution of outcomes is determined by the equilibrium of the underlying
game.  The goal is to estimate how the players' utility for each possible
outcomes varies as a function of observed variables.  These models are
appropriate for situations where the ultimate outcome following one actor's
choice depends on actions taken by another, which are common in social science.
In such cases, standard estimators like binary-choice regression or Heckman
selection models will lead to incorrect inferences
\citep{Signorino2002,Signorino2003a}.  The \pkg{games} package currently
implements full information maximum likelihood estimation functions for four
models of strategic choice:
\begin{itemize}
  \item \code{egame12}, a discrete extensive form game with two players
  and three terminal nodes.
  \item \code{egame122}, a discrete extensive form game with two
  players and four terminal nodes.
  \item \code{egame123}, a discrete extensive form game with three
  players and four terminal nodes.
  \item \code{ultimatum}, the ultimatum bargaining game.
\end{itemize}
The package also provides various post-estimation functions, including
convergence checks, plotting of fitted values, and non-nested model comparison
tests.

The models available in the \pkg{games} package are those that have been used
most widely in the analysis of strategic interaction within the political
science literature (see the citations in Section~\ref{sec:models}).  For
analysis of other models with a recursive structure, \citet{Bas2007} provide a
multi-stage method similar to
\citeauthor{Heckman1979tb}'s~\citeyearpar{Heckman1979tb} two-step estimator for
selection models.  This method, statistical backward induction, uses only
logistic or probit regression and can be easily implemented in virtually any
statistical software.  However, like the Heckman two-step estimator, statistical
backward induction is inefficient relative to full information maximum
likelihood.  The purpose of the \pkg{games} package is to provide efficient
maximum likelihood estimation for the most common models of strategic choice.

Estimation of strategic statistical models was previously implemented in
\proglang{Gauss} in the \pkg{Strat} package \citep{stratgauss}.  The \pkg{games}
package provides new models and additional post-estimation functionality over
that available in \pkg{Strat}, and it is implemented in the popular \proglang{R}
language.

Section~\ref{sec:models} of this paper provides a brief introduction to
strategic statistical models, including a derivation of a simple example.
Section~\ref{sec:spec-est} discusses the details of their implementation in the
\pkg{games} package and provides a replication of \citet{Leblang2003}.  The
post-estimation functionality is covered in Section~\ref{sec:post}.

\section{Strategic statistical models}
\label{sec:models}

Strategic statistical models were first introduced to analyze international
crises and the outbreak of war \citep{Signorino1999}.  Signorino shows that
standard techniques like logistic regression are inappropriate when applied to
data generated by multi-agent strategic interactions, a point developed further
by \citet{Signorino2003a}.  \citet{Signorino2003} introduces a class of models
that yield consistent estimates of players' utilities when the structure of
interaction is known.  These models have since been applied to data on U.S.\
congressional races \citep{Carson2003,Carson2005}, currency markets
\citep{Leblang2003}, armed deterrence \citep{Signorino2006}, international
economic sanctions \citep{McLean2010}, territorial conflict \citep{Carter2010a},
and Latin American governmental crises \citep{Helmke2010}.

Every strategic model is associated with a game form and solution concept.
First, the structure of the interaction must be known: the number of players,
the order in which they move, the number of actions each has available, and the
possible outcomes.  The purpose is to estimate players' utilities for each
outcome, usually as a function of covariates, from data on observed outcomes of
the game being played.  This requires the introduction of a stochastic
component, so that there is a non-degenerate probability distribution over
outcomes for any given set of coefficients (i.e., those on the covariates
describing players' utilities).  In particular, we will specify where error
enters the model and calculate the equilibrium outcome for each given set of
parameters and stochastic shocks, using the appropriate solution concept for the
assumed stochastic structure (see below).  The probability of each outcome can
then be obtained by assuming a distribution for the error terms.

The choice of stochastic structure is crucial for the estimation and
interpretation of utility parameters.  The \pkg{games} package implements
methods for two cases:
\begin{description}
  \item[Agent error] Each player's utility over outcomes is fixed and common
  knowledge.  However, there are perceptual or implementation errors that can
  lead to a player not choosing the action that maximizes her expected utility
  calculated in terms of the outcome payoffs.  This can be represented as a
  shock $\alpha_{mj}$ to Player $m$'s expected utility for taking action $j$,
  where the shock is realized immediately before $m$ makes her action choice
  (and hence is unknown to the preceding players).  We typically assume that
  each $\alpha_{mj}$ is drawn independently from a normal or logistic
  distribution.  The solution concept under agent error is quantal response
  equilibrium \citep{McKelvey1998}, wherein each player anticipates the
  probability of ``mistakes'' by the others and adjusts her expectations
  accordingly.

  \item[Private information] There is a different stochastic shock to each
  player's utility for each outcome.  We will write this as $\pi_{mk}$, for
  Player $m$ and outcome $k$.  The key assumption is that each player fully
  knows her utility for each outcome, but only knows the distribution of the
  shocks to the other players' outcome utilities.  The solution concept in this
  case is perfect Bayesian equilibrium: each player takes the action that gives
  her the highest expected utility, with respect to the realized shocks to her
  preferences and her expectations about the actions the other players will
  take.  Whereas the distribution over outcomes was induced by the possibility
  of wrong decisions in the agent error case, now it comes from the fact that
  observationally indistinguishable players may have different privately known
  preferences.  Except in the statistical ultimatum model, we will assume that
  each $\pi_{mk}$ is drawn from a normal distribution.
\end{description}
We illustrate both of these stochastic structures in the \code{egame12} example
below. \citet{Signorino2003} discusses these in greater depth, and concludes
from Monte Carlo experiments that models of the two types do not yield
appreciably different results when the underlying game form is relatively
simple.

\subsection[Illustration: The egame12 model]%
{Illustration: The \code{egame12} model}
\label{sec:egame12}

\begin{figure}[tp]
  \centering
  \subfloat[Agent error]%
  {\includegraphics[width=0.55\textwidth]{img/egame12agent-crop}}
  
  \subfloat[Private information]%
  {\includegraphics[width=0.5\textwidth]{img/egame12private-crop}}
  \caption{Game trees for the \code{egame12} model.}
  \label{fig:egame12-trees}
\end{figure}

The \code{egame12} model, with two players and three possible outcomes, is the
simplest strategic model.  The players are indexed $m = 1, 2$, and each has an
action set $a_m = \{L, R\}$.  The outcomes are indexed $Y = 1, 3, 4$.  The
structure of the interaction is as follows:
\begin{enumerate}
  \item Player $1$ chooses his action $a_1$.  If $a_1 = L$, the game ends and
  the outcome is $Y = 1$.  Otherwise, if $a_1 = R$, Player 2 gets to move.
  \item Player $2$ chooses her action $a_2$.  If $a_2 = L$, the outcome is $Y =
  3$; if $a_2 = R$, the outcome is $Y = 4$.
\end{enumerate}
These are illustrated in the game trees in Figure~\ref{fig:egame12-trees}.
Let $p_1$ and $p_2$ denote the action probabilities for Player 1, where $p_1 =
\Prob(a_1 = L)$ and $p_2 = \Prob(a_2 = R)$.  Let Player 2's action
probabilities, conditional on 2's move being reached, be $p_3 = \Prob(a_2 = L |
a_1 = R)$ and $p_4 = \Prob(a_2 = R | a_1 = R)$.

Each player's utility depends on the outcome of the game; utility to Player $m$
for outcome $k \in \{1, 3, 4\}$ is denoted $U_{mk}$.  When estimating this game,
we usually model each of these utilities as a linear function of known
covariates, $U_{mk} = x_{mk}^{\top} \beta_{mk}$, with the goal of estimating the
coefficients $\beta_{mk}$.  Each player chooses her action $a \in \{L, R\}$ to
maximize her expected utility, $\E U_m(a)$.  Since Player 2 moves last, her
expected utilities are simply $\E U_2(L) = U_{23}$ and $\E U_2(R) = U_{24}$.
Similarly, since the action $a_1 = L$ is a game-ending move, Player 1's expected
utility from this is $\E U_1(L) = U_{11}$.  However, Player 1's expected utility
from the action $R$ depends on Player 2's choice, so we have $\E U_1(R) = p_3
U_{13} + p_4 U_{14}$.

We observe $N$ plays of the game, each with realized outcome $Y_i$ and
associated regressors $x_{mki}$ for each player $m$ and outcome $k$.  Our goal
is to estimate $\beta = (\beta_{mk})_{m \in \{1, 2\}, k \in \{1, 3, 4\}}$, the
set of coefficients describing players' utilities for particular outcomes, via
maximum likelihood.  Once we assume a stochastic structure (agent error or
private information), we can calculate the observation-wise choice probabilities
$p_{1i}, \ldots, p_{4i}$ for any $\beta$.  The log-likelihood is then
\begin{equation}
  \label{eq:log-lik}
  \log \ell(\beta \,|\, X, Y) = \sum_{Y_i = 1} \log p_{1i} + \sum_{Y_i = 3}
  (\log p_{2i} + \log p_{3i}) + \sum_{Y_i = 4} (\log p_{2i} + \log p_{4i}).
\end{equation}
The calculation of these choice probabilities is the subject of the following
subsections.

\subsubsection{Agent error}

Consider observation $i \in \{1, \ldots, N\}$ and assume that each player
receives a stochastic shock $\alpha_{mji}$ to her expected utility for choosing
$j \in \{L, R\}$, where each $\alpha_{mji}$ is drawn independently from a normal
distribution with mean $0$ and variance $\sigma^2$.\footnote{The same
  calculations as follow can be applied in the case of errors with logistic
  distributions.}  To solve for the quantal response equilibrium of the game, we
will proceed via backward induction, solving for Player $2$'s choice
probabilities in order to find Player $1$'s.

If Player $2$'s turn is reached, her choice determines the outcome for sure.  We
thus have $\E U_{2i}(L) = U_{23i} = x_{23i}^{\top} \beta_{23}$ and $\E
U_{2i}(R) = U_{24i} = x_{24i}^{\top} \beta_{24}$.  The \textit{ex ante}
probability that Player $2$ chooses $R$ is
\begin{equation}
  \label{eq:p4-agent}
  \begin{aligned}
    p_{4i} &= \Prob[ \E U_{2i}(R) + \alpha_{2Ri} \geq \E U_{2i}(L) + \alpha_{2Li}] \\
    &= \Prob [ \alpha_{2Li} - \alpha_{2Ri} \leq x_{24i}^{\top} \beta_{24} -
    x_{23i}^{\top} \beta_{23} ] \\
    &= \Phi \left( \frac{x_{24i}^{\top} \beta_{24} - x_{23i}^{\top}
        \beta_{23}}{\sigma \sqrt{2}} \right),
  \end{aligned}
\end{equation}
where $\Phi(\cdot)$ is the standard normal CDF.  Since Player $2$ must choose
from $L$ or $R$, we have $p_{3i} = 1 - p_{4i}$.  We now can solve for Player
$1$'s choice probabilities.  If Player $1$'s action is $L$, the outcome is $Y_i
= 1$ for certain.  However, if he chooses $R$, the outcome is a lottery over
outcomes $3$ and $4$, with probabilities $p_{3i}$ and $p_{4i}$ respectively.
Since Player $1$ also receives a shock to his expected utilities by action, his
\textit{ex ante} chance of choosing $R$ is
\begin{equation}
  \label{eq:p2-agent}
  \begin{aligned}
    p_{2i} &= \Prob[ \E U_{1i}(R) + \alpha_{1Ri} \geq \E U_{1i}(L) + \alpha_{1Li}] \\
    &= \Prob [ \alpha_{1Li} - \alpha_{1Ri} \leq p_{3i} x_{13i}^{\top}
    \beta_{13} + p_{4i}
    x_{14i}^{\top} \beta_{14} - x_{11i}^{\top} \beta_{11} ] \\
    &= \Phi \left(\frac{p_{3i} x_{13i}^{\top} \beta_{13} + p_{4i} x_{14i}^{\top}
        \beta_{14} - x_{11i}^{\top} \beta_{11}}{\sigma \sqrt{2}} \right).
  \end{aligned}
\end{equation}
Because Player $1$ must choose $L$ or $R$, we have $p_{1i} = 1 - p_{2i}$.  We
can then estimate the agent error model for a given dataset by substituting
Equations~\ref{eq:p4-agent} and \ref{eq:p2-agent} into the log-likelihood
function, Equation~\ref{eq:log-lik}.

As in standard binary dependent variable models (e.g., GLMs with a logit or
probit link), the statistical model is not identified with respect to the scale
parameter $\sigma$, so it cannot be estimated \citep{Signorino1999,Lewis2003}.
The scale parameter is fixed to $\sigma = 1$ in all of the extensive-form models
in \pkg{games}, so each estimated utility coefficient $\hat{\beta}_{mkj}$ can be
interpreted as an estimate of the ratio $\beta_{mjk} / \sigma$.  Alternatively,
we allow for $\sigma$ to be modeled as a function of covariates, in which case
the regression coefficients for these variables can be estimated.  For details,
see the example in Section~\ref{sec:fitting}.

\subsubsection{Private information}

Assume there is an additive shock $\pi_{mki}$ to each outcome utility $U_{mki}$,
where each $\pi_{mki}$ is drawn independently from a normal distribution with
mean $0$ and variance $\sigma^2$.  We will again proceed by backward induction,
this time to solve for the perfect Bayesian equilibrium.

Player $2$ will choose $R$ if and only if $U_{24i} + \pi_{24i} \geq U_{23i} +
\pi_{23i}$.  The \textit{ex ante} probability of Player $2$ choosing $R$ is
therefore
\begin{equation}
  \label{eq:p4-private}
  \begin{aligned}
    p_{4i} &= \Prob[ U_{24i} + \pi_{24i} \geq U_{23i} + \pi_{23i} ] \\
    &= \Prob[ \pi_{23i} - \pi_{24i} \leq x_{24i}^{\top} \beta_{24} -  x_{23i}^{\top}
    \beta_{23} ] \\
    &= \Phi \left(\frac{x_{24i}^{\top} \beta_{24} -  x_{23i}^{\top}
        \beta_{23}}{\sigma \sqrt{2}}\right).
  \end{aligned}
\end{equation}
As before, $p_{3i} = 1 - p_{4i}$.  We can now write Player 1's expected utility
for choosing $R$ in the private information case as
\begin{displaymath}
  \E U_{1i}(R) = p_{3i} (x_{13i}^{\top} \beta_{13} + \pi_{13i}) + p_{4i} (x_{14i}^{\top}
  \beta_{14} + \pi_{14i}).
\end{displaymath}
The \textit{ex ante} probability of Player $1$ selecting $R$ is
\begin{equation}
  \label{eq:p2-private}
  \begin{aligned}
    p_{2i} &= \Prob[ \E U_{1i}(R) \geq \E U_{1i}(L) ] \\
    &= \Prob[ p_{3i} (x_{13i}^{\top} \beta_{13} + \pi_{13i}) + p_{4i} (x_{14i}^{\top}
    \beta_{14} + \pi_{14i}) \geq x_{11i}^{\top} \beta_{11} + \pi_{11i}] \\
    &= \Prob[ \pi_{11i} - p_{3i} \pi_{13i} - p_{4i} \pi_{14i} \leq p_{3i} x_{13i}^{\top}
    \beta_{13} + p_{4i} x_{14i}^{\top} \beta_{14} - x_{11i}^{\top} \beta_{11} ] \\
    &= \Phi \left( \frac{p_{3i} x_{13i}^{\top} \beta_{13} + p_{4i} x_{14i}^{\top}
        \beta_{14} - x_{11i}^{\top} \beta_{11}}{\sigma \sqrt{1 + p_{3i}^2 + p_{4i}^2}}
    \right).
  \end{aligned}
\end{equation}
Then, as in the agent error case, we can estimate the model by letting $p_{1i} = 1
- p_{2i}$ and substituting Equations~\ref{eq:p4-private} and~\ref{eq:p2-private}
into the log-likelihood function, Equation~\ref{eq:log-lik}.  As before, for
identification we must either set $\sigma = 1$ or model $\sigma$ as a function
of regressors.

The agent error and private information models are very similar, but not
observationally equivalent.  Equations~\ref{eq:p4-agent} and~\ref{eq:p4-private}
are identical, so the action probabilities for Player 2 are the same under
either model (holding fixed $\beta$).  However, the expressions for Player 1's
choice probabilities, Equations~\ref{eq:p2-agent} and~\ref{eq:p2-private}, are
slightly different.  In the agent error case, the choice probability for Player
1 depends on the difference in expected utility shocks, $\alpha_{1Li} -
\alpha_{1Ri}$, which is identically distributed across observations $i \in \{1,
\ldots, N\}$.  In the private information model, the probability depends on the
difference of the weighted outcome utility shocks, $\pi_{11i} - p_{3i} \pi_{13i}
- p_{4i} \pi_{14i}$.  This is normally distributed with mean $0$ regardless of
the values of $p_{3i}$ and $p_{4i}$, but its variance is $1 + p_{3i}^2 +
p_{4i}^2$ and thus may vary across observations.  In particular, the variance is
least when $p_{3i} = p_{4i} = 0.5$ and greatest when $p_{3i} = 1$ or $p_{4i} =
1$.  In practice, this does not make for a major difference, and the two models
almost always yield similar estimates of $\beta$.


\subsection{Identification of model parameters}

\citet{Lewis2003} provide a necessary condition for identification in
discrete-choice strategic models: no regressor, including the constant, may
appear in all of a player's utility equations for the outcomes reachable after
her move.  All of the fitting functions in the \pkg{games} package enforce this
condition.  One way to accomplish it is to fix each player's utility to $0$ for
one outcome.  This comes without loss of generality, since Von
Neumann--Morgenstern utilities are unique only up to a positive affine
transformation.

The necessary condition is sufficient if there is enough variation in the
regressor and outcome data.  As an example of insufficient variation in the
regressors, consider the \code{egame12} model with:
\begin{align*}
  U_{11i} &= \beta_{110} + \beta_{111} x_i, \\
  U_{13i} &= 0, \\
  U_{14i} &= \beta_{140} + \beta_{141} x_i, \\
  U_{23i} &= 0, \\
  U_{24i} &= \beta_{240},
\end{align*}
where $x$ is a binary covariate.  This specification meets the necessary
condition, since $U_{13}$ and $U_{23}$ are both fixed to $0$.  We have that
$p_{4i} = \Phi(\beta_{240}/\sqrt{2}) \equiv p_4$ for all $i$.  Let $b$ be any
real number and consider the alternative parameters
\begin{displaymath}
  \tilde{\beta} =
  \begin{pmatrix}
    \tilde{\beta}_{110} \\ \tilde{\beta}_{111} \\ \tilde{\beta}_{140} \\
    \tilde{\beta}_{141} \\ \tilde{\beta}_{240}
  \end{pmatrix}
  =
  \begin{pmatrix}
    \beta_{110} \\ \beta_{111} + b \\ \beta_{140} \\ \beta_{141} + b/p_4 \\
    \beta_{240}
  \end{pmatrix}.
\end{displaymath}
It is easily verified from Equations~\ref{eq:p4-agent} and~\ref{eq:p2-agent}
(for the agent error model) or Equations~\ref{eq:p4-private}
and~\ref{eq:p2-private} (for the private information model) that the choice
probabilities are the same for all observations under $\beta$ and
$\tilde{\beta}$.  The two sets of parameters are thus observationally
equivalent, so the model parameters are not identified.  This kind of
identification problem is averted if there is at least one continuous covariate
included in the model, as then $x_i \neq x_j$ for all distinct observations $i,
j$.  For other examples of identification failure due to insufficient variation
in the covariates, see \citet{Lewis2003}.

The other identification problem that may arise is separation, a common issue in
models of discrete choice \citep{Albert1984aa}.  For example, in the
\code{egame12} model, suppose there is a covariate $x_j$ (or more generally a
linear combination of covariates) that enters Player 2's utility such that
\begin{displaymath}
  a_{2i} =
  \begin{cases}
    L & x_{ji} \leq \hat{x}, \\
    R & x_{ji} > \hat{x}
  \end{cases}
\end{displaymath}
for some critical value $\hat{x}$.  Then, as in ordinary logistic or probit
regression models, maximum likelihood estimates of the parameters associated
with this covariate do not exist.  In practice, the fitting procedure will tend
toward infinity and typically fail to converge.  This condition is trivially
true if one of the outcomes of a model is not observed, so another necessary
condition for existence of an MLE is that each outcome be observed at least once
in the data.

In addition to these global identifiability issues, there is also the potential
that a numerical maximization procedure will stop at a point where the parameter
estimates are not locally identified (e.g., a saddle point).  A sufficient
condition for local identification is that the Hessian matrix at $\hat{\beta}$
be negative definite, so that this estimate is a strict local maximum.  All
fitting functions in the \pkg{games} package check for negative definiteness of
the Hessian matrix and issue a warning if this condition is not satisfied.


\subsection{The statistical ultimatum model}

The ultimatum game is a workhorse model of bargaining in economics in political
science, in which one player makes a ``take it or leave it'' offer to the other.
The equilibrium size of an offer depends on the proposer's expectations about
what will be accepted, which standard models like OLS fail to account for.  To
facilitate analysis of bargaining data, we implement the statistical ultimatum
game of \citet{Ramsay2009} via the \code{ultimatum} function.  The structure of
the game is:
\begin{enumerate}
  \item Player 1 makes an offer $x \in [0, Q]$ to Player 2.
  \item Player 2 can accept or reject the offer.
  \begin{enumerate}
    \item If accepted, payoffs are $Q - x$ for Player 1 and $x$ for Player 2.
    \item If rejected, payoffs are $R_1 + \epsilon_1$ and $R_2 + \epsilon_2$
    respectively, where $\epsilon_1, \epsilon_2$ are i.i.d.\ logistic variables
    with scale parameters $s_1$ and $s_2$.  The reservations $R_m$ are common
    knowledge, but the realized stochastic terms $\epsilon_m$ are privately
    known by the players.
  \end{enumerate}
\end{enumerate}
In applications, the reservation values are modeled as a function of covariates,
$R_{mi} = x_{mi}^{\top} \beta_m$, and the goal is to estimate $\beta_1$,
$\beta_2$, $s_1$, and $s_2$.  For example, experimental economists have
investigated whether there are cross-cultural differences in play of the
ultimatum game in lab settings; e.g., if Americans make systematically lower
offers \citep[see][]{Botelho2005}.  To test this, one would include an indicator
for nationality in the equations for the players' reservation values.

The log-likelihood of the ultimatum model can be derived as follows \citep[for
full details, see][]{Ramsay2009}.  First, the probability that Player 2 accepts
a given offer $y$ is
\begin{align*}
  \Prob(\text{accept} \,|\, y)
  &= \Prob(y \geq R_2 + \epsilon_2) \\
  &= \Prob(\epsilon_2 \leq y - R_2) \\
  &= \Lambda(y - x_2^\top \beta_2; s_2),
\end{align*}
where $\Lambda(\cdot; s)$ is the logistic c.d.f.\ with scale parameter $s$.  We
can then characterize $y^* = h(\epsilon_1)$, the unconstrained optimal offer for
Player 1 with private shock $\epsilon_1$, as the solution to the concave
optimization problem
\begin{displaymath}
  \max_y \:
  \Prob(\text{accept} \,|\, y) \cdot (Q - y)
  + (1 - \Prob(\text{accept} \,|\, y)) \cdot (R_1 + \epsilon_1).
\end{displaymath}
After differentiating and rearranging, we yield the implicit definition
\begin{align*}
  y^* &= Q - x_1^\top \beta_1 - \epsilon_1
  - \frac{
    \Lambda(y^* - x_2^\top \beta_2; s_2)
  }{
    \lambda(y^* - x_2^\top \beta_2; s_2)
  } \\
  &= Q - x_1^\top \beta_1 - \epsilon_1 - s_2 \left[
    1 + e^{(y^* - x_2^\top \beta_2)/s_2}
  \right],
\end{align*}
where $\lambda(\cdot; s)$ is the logistic p.d.f.\ with scale parameter $s$.
Finally, by transforming the distribution of $\epsilon_1$, we obtain expressions
for the p.d.f.\ and c.d.f.\ of $y^*$:
\begin{align*}
  f(y^*) &=
  \frac{
    \left[
      1 + e^{(y^* - x_2^\top \beta_2)/s_2}
    \right]
    e^{-\left\{
        Q - y^* - x_1^\top \beta_1 - s_2 \left[
          1 + \exp((y^* - x_2^\top \beta_2)/s_2)
        \right]
      \right\} / s_1
    }
  }{
    s1 \left[
      1 +
      e^{-\left\{
          Q - y^* - x_1^\top \beta_1 - s_2 \left[
            1 + \exp((y^* - x_2^\top \beta_2)/s_2)
          \right]
        \right\} / s_1
      }
    \right]^2
  }; \\[0.4em]
  F(y^*) &=
  \frac{
    1
  }{
    1 + 
    e^{\left\{
        Q - y^* - x_1^\top \beta_1 - s_2 \left[
          1 + \exp((y^* - x_2^\top \beta_2)/s_2)
        \right]
      \right\} / s_1
    }
  }.
\end{align*}
Due to the constraint that offers must be between $0$ and $Q$, the observed
offer will be $y = 0$ if $y^* < 0$ and $y = Q$ if $y^* > Q$.  Letting $\delta_i$
be an indicator for whether the offer was accepted in observation $i$, we yield
the log-likelihood
\begin{equation}
  \label{eq:loglik-ult}
  \begin{aligned}
    \log \ell(\beta_1, \beta_2, s_1, s_2 \,|\, y, X, \delta)
    &= \sum_{y_i = 0} \log F(0) + \sum_{y_i \in [0, Q]} \log f(y_i) + \sum_{y_i
      = Q} \log (1 - F(Q)) \\
    &\quad + \sum_{\delta_i = 0} \log (1 - \Prob(\text{accept} \,|\, y_i))
    + \sum_{\delta_i = 1} \log \Prob(\text{accept} \,|\, y_i).
  \end{aligned}
\end{equation}


\section{Specification and estimation}
\label{sec:spec-est}

In this section and those below, we replicate \citeauthor{Leblang2003}'s
\citeyearpar{Leblang2003} analysis of speculative currency attacks to illustrate
the package's functionality.  The dataset is available in \pkg{games} as
\code{leblang2003}.
<<loadleb>>=
library("games")
data("leblang2003")
names(leblang2003)
@ %
Each observation is a country observed in a particular year.  The assumed
data-generating process follows the \code{egame12} model, with two players and
three potential outcomes.  Player $1$ is ``the market,'' which decides whether
or not to initiate a speculative attack on Player $2$'s (the country's)
currency.  If the market decides not to attack, the game ends.  If there is an
attack, the country decides whether to devalue the currency or defend its
exchange-rate peg.  The observed distribution of outcomes is:
<<lebtab>>=
table(leblang2003$outcome)
@ %
We assume that the market is strategic, incorporating its
expectations of the country's response into its initial decision of whether to
make a currency attack.  The source of uncertainty is assumed to be private
information about payoffs, which yields outcome probabilities given by
Equations~\ref{eq:p4-private} and \ref{eq:p2-private}.  The market's utility
for the three possible outcomes, and each country's utility for defending the
currency, is assumed to be a linear function of observed covariates.  For
identification, the country's utility for devaluation is fixed to
$0$.\footnote{In the original study, Leblang estimates a constant for Player
  $2$'s utility from devaluation and leaves a constant out of utility for
  defense.  Our approach here yields substantively identical results.}  See the
original paper or the help page for \code{leblang2003} for information on the
covariates and specific assignments to each utility equation.

\subsection{Modeling player utilities}

The typical use of a strategic model is to estimate the effect of observed
factors on players' utility for each possible outcome.  To avoid an
overabundance of parameters and potential inefficiency, analysts will typically
want to make some exclusion restrictions---i.e., to leave some regressors out of
some utility equations.  This necessitates the use of multiple model formulas,
which we handle via the \pkg{Formula} package \citep{Formulapkg}.  The variables
to include in each utility are specified using the standard \code{formula}
syntax, and each set is separated by a vertical bar (\code{|}).  For example, in
the \code{egame12} model, an analyst may want to use the specification
\begin{align*}
  U_{11} &= \beta_{11,0} + \beta_{11,1} x_1 \\
  U_{13} &= 0 \\
  U_{14} &= \beta_{14,0} + \beta_{14,1} x_1 + \beta_{14,2} x_2 \\
  U_{24} &= \beta_{24,0} + \beta_{24,2} x_2,
\end{align*}
where $x_1$ and $x_2$ are observed variables.  The appropriate \code{Formula}
syntax is \code{y ~ x1 | 0 | x1 + x2 | x2}.

In some of the more complex models, such as \code{egame123} with its eight
utility equations, writing the model formulas manually may be daunting or prone
to error.  We provide two options to ease the process.  First, users may specify
the model formulas as a list; the fitting functions then use the internal
function \code{checkFormulas} to convert it to the appropriate \code{Formula}
object.
<<formulaAsList>>=
f1 <- list(u11 = y ~ x1, u13 = ~ 0, u14 = ~ x1 + x2, u24 = ~ x2)
games:::checkFormulas(f1)
@ %
(Elements of the list need not be named; in fact, the names are ignored.)
Second, the function \code{makeFormulas} provides interactive prompts for
constructing the model formulas step by step.  The user only needs to supply the
name of the model he or she intends to fit and a character vector containing
outcome descriptions.  For the Leblang data, the appropriate call would look
like \code{makeFormulas(egame12, outcomes = c("no attack", "devaluation",
"defense"))}.  The following menu will appear at the \proglang{R} console:
\begin{Code}
Equation for player 1's utility from no attack: 

1: fix to 0
2: intercept only
3: regressors, no intercept
4: regressors with intercept

Selection: 
\end{Code}
If \code{3} or \code{4} is selected, the user will be prompted to enter a
space-separated list of variables to include in the utility equation of
interest.  We use functions from \pkg{stringr} \citep{stringrpkg} in parsing the
input.  The same menu will then be displayed for player 1's utility from
devaluation, player 1's utility from defense, and player 2's utility from
defense.  The final prompt will ask for the name of the variable (or variables;
see Section~\ref{sec:dep} below) containing information on the observed
outcomes.  The function will then return the \code{Formula} specification
corresponding to the given input, which can be supplied as the \code{formulas}
argument of the appropriate fitting function.

\subsection{Dependent variable specification}
\label{sec:dep}

For most of the models included in the \pkg{games} package, there are a few
different ways that the dependent variable might be stored in the dataset.  For
example, all of the following are plausible representations of the outcome
variable in the Leblang data:
\begin{itemize}
  \item Numeric indicators for the final outcome, where \code{1} means no
  currency attack, \code{2} means devaluation in response to an attack, and
  \code{3} means defense against an attack.
  \item Factor indicators for the final outcome, where the levels correspond to
  no attack, devaluation, and defense respectively.
  \item Binary variables representing each player's action.  The first would be
  coded \code{0} when there is no attack and \code{1} when there is an attack.
  The second would be coded \code{0} when the targeted country devalues and
  \code{1} when it defends the currency peg.
\end{itemize}
The \pkg{games} package allows for all of these types of specifications.  To use
a numeric or factor indicator for the final outcome, the form of the
specification is simply \code{y ~ .}, as in typical model formulas.  To use
binary indicators, the names of the indicators should be separated with \code{+}
signs on the left-hand side, as in \code{y1 + y2 ~ .}.  When using binary
indicators, unobserved outcomes---in this case, the value of \code{y2} when
\code{y1 == 0}---should \emph{not} be coded as \code{NA}s, as this will
typically result in their being removed from the dataset.

The method of specifying the dependent variable has no effect on the estimation
results, as shown in the next example.
<<depvar,cache=true>>=
leblang2003$attack <- as.numeric(leblang2003$outcome != "no attack")
leblang2003$defend <- as.numeric(leblang2003$outcome == "defense")
flb <- outcome ~ capcont + lreserves + overval + creditgrow + USinterest +
    service + contagion + prioratt - 1 | 1 | 1 | unifgov + lexports + preelec +
    postelec + rightgov + realinterest + capcont + lreserves
flb1 <- as.Formula(flb)
flb2 <- update(flb1, attack + defend ~ .)

leb1 <- egame12(flb1, data = leblang2003, link = "probit", type = "private")
leb2 <- egame12(flb2, data = leblang2003, link = "probit", type = "private")
@ %
<<printdepvar>>=
all.equal(coef(leb1), coef(leb2), check.attributes = FALSE)
@ %
The only difference is in the construction of the names of the utility
equations.  When binary action indicators are used, the outcome names are
inferred from the names of the action variables.  When numeric or factor outcome
variables are used, their values/levels are used as the outcome names.
<<depvarnames>>=
cbind(leb1$equations, leb2$equations)
@ %
The methods for specifying the dependent variable differ slightly
across models; see the help page of each fitting function for a list of
allowable specifications.

\subsection{Model fitting}
\label{sec:fitting}

Once the formula has been constructed, it is straightforward to fit a strategic
model.  All of the fitting functions contain the arguments \code{data},
\code{subset}, and \code{na.action}, which are used in the typical way to
construct the model frame.  In addition, the \code{method} argument is passed to
\code{maxLik} (from the \pkg{maxLik} package; \citealt{maxLikpkg}) to select an
optimization routine, and other parameters to control the process (e.g.,
\code{reltol}, \code{iterlim}) can be passed as named arguments.

Each fitting function returns an object inheriting from two S3 classes.  The
first is the \code{"game"} class, for which most of the methods of interest are
defined, including \code{print} and \code{summary}.  The second is the name of
the particular model that was fit; this is used by the \code{predict} methods.
For the most part, the elements of a \code{"game"} object are the same as those
of \code{"lm"} and \code{"glm"} objects (e.g., \code{coefficients},
\code{vcov}).  Pertinent differences include:
\begin{itemize}
  \item The \code{log.likelihood} element contains the vector of the $n$
  observationwise log-likelihoods evaluated at the parameter estimate, for use
  in non-nested model tests (see Section~\ref{sec:non-nest} below).
  \item The \code{y} element contains the outcome variable represented as a
  factor whose levels are the outcome names.
  \item The \code{link} and \code{type} elements store the link function and
  source of error respectively.
  \item The \code{equations} element contains the names of the utility equations
  and scale terms; this is used by \code{print.game} and \code{latexTable} to
  group the parameters estimated.
\end{itemize}
Fitted \code{ultimatum} models contain some additional elements, which are
discussed below.

The nonparametric bootstrap is implemented as part of the fitting process via
the \code{boot} argument of the model functions.  To run the bootstrap on a
model that has already been estimated, use \code{update} as in the next example.
A status bar is printed by default, but it can be suppressed by setting
\code{bootreport = FALSE}.
<<boot,cache=true>>=
set.seed(42)  # for reproducibility
leb1 <- update(leb1, boot = 100)
@ %
% doing this manually b/c no printing from cached blocks
\begin{Code}
Running bootstrap iterations...
========================================================================
\end{Code}
Bootstrap results are stored in the \code{boot.matrix} element of the fitted
model object.  When a model has been bootstrapped, the default behavior of
\code{summary.game} is to use the bootstrap results to calculate standard error
estimates.
<<printboot>>=
summary(leb1)
@ %
To see the normal-theory standard errors instead, supply the option
\code{useboot = FALSE} to the \code{summary} call.

The other arguments for the fitting functions depend on whether the model is one
of the discrete extensive form games or the statistical ultimatum game.

\subsubsection{Extensive-form models}

The stochastic structure of the extensive-form models is specified via the
arguments \code{link} and \code{type}.  The \code{link} argument is used to
specify the distributional form of the error terms: \code{"probit"} for normal,
\code{"logit"} for type I extreme value.  The \code{type} argument specifies
whether the source of randomness is \code{"agent"} error or \code{"private"}
information.  Normal errors must be used in the case of private information; if
a model is specified with \code{link = "logit"} and \code{type = "private"}, a
warning will be issued and a probit link will be enforced.

The error variance $\sigma$ normally is not estimable on its own, as noted above
in Section~\ref{sec:models}.  This is no longer the case if $\sigma$ is modeled
as function of known covariates:
\begin{displaymath}
  \sigma = \exp(\gamma_1 Z_1 + \gamma_2 Z_2 + \ldots + \gamma_k Z_k).
\end{displaymath}
The argument \code{sdformula} is used to estimate $\gamma$ for such a model.
The formula should be one-sided, with nothing to the left of the \code{~}, as in
the following example with the Leblang data.
<<sdform,cache=true>>=
leb3 <- egame12(outcome ~ lreserves + overval - 1 | 1 | 1 | preelec +
                realinterest, sdformula = ~ prioratt - 1, data = leblang2003,
                link = "probit", type = "private")
@ %
<<printsdform>>=
summary(leb3)
@ %
The equation for the scale parameter coefficients is \code{log(sigma)}; for
models with a logit link, it would be \code{log(lambda)}.  The positive
coefficient on prior attacks indicates that outcomes are less predictable (since
the stochastic terms are larger relative to the systematic components) for
countries that have been victims of speculative currency attacks in the past.
Note that it is also possible to estimate separate scale-term equations for each
player, by using the argument \code{sdByPlayer = TRUE} and using an equation of
the form \code{sdformula = scale1vars | scale2vars}.

The extensive-form models also allow for estimation of the error variance when
the average payoffs are known to the analyst, such as in data from lab
experiments.  In this case, the payoffs can be specified with the
\code{fixedUtils} argument.  The only information needed from the model formula
is the outcome variable, so the \code{formulas} argument can be written in the
form \code{y ~ .} or \code{y ~ 1}.  When the argument \code{fixedUtils} is used,
the default behavior is to estimate a single common scale parameter, as in the
next example.
<<fixedutils,cache=true>>=
lebfixed <- egame12(outcome ~ ., data = leblang2003,
                    fixedUtils = c(1, -1, 0, 1), link = "probit", type =
                    "private")
@ %
<<printfixedutils>>=
summary(lebfixed)
@ %
Loosely speaking, the higher the estimated scale parameter relative to the
utility values, the greater the role of uncertainty in each player's
decisions. As before, \code{sdByPlayer} can be used to estimate a separate scale
parameter for each player, and \code{sdformulas} to specify the scale term(s) as
a function of covariates.

\subsubsection[The ultimatum model]{The \code{ultimatum} model}

In the ultimatum model, each observation consists of the value of the offer made
by Player 1 and whether Player 2 accepted it.  By assumption, there is an
exogenous upper bound on the size of the offer, which is specified via
\code{maxOffer}.  The lower bound is always 0.  It is important to be able to
identify which offers were at one of these boundary points, since the
log-likelihood of an observation depends on whether the offer was interior.  If
offers are stored as floating-point numbers, naive equality tests may
misclassify some boundary observations as interior.  To mitigate this, we use
the argument \code{offertol} and code an offer $x$ as meeting the lower bound if
$x < \mbox{\code{offertol}}$ and the upper bound if $x > \mbox{\code{maxOffer}}
- \mbox{\code{offertol}}$.  Unless there are extremely slight differences
between observed offers, on the order of $1 \times 10^{-8}$, the default value
of \code{offertol} should suffice for most analyses.

The arguments \code{s1} and \code{s2} are for fixing the scale parameters of the
stochastic component of the players' reservation values.  If either of these is
left unspecified, it is estimated.  We recommend fixing \code{s2}, since
attempts to estimate it often run into numerical stability issues
\citep{Ramsay2009}.

The model formula for \code{ultimatum} should be written in the form \code{offer
  + accept ~ R1 | R2}, where \code{R1} and \code{R2} contain the variables for
Player 1's and 2's reservation values respectively.  Some researchers may only
have access to data on offer size, but not whether the offer was accepted.  For
such datasets, run \code{ultimatum} with the argument \code{outcome = "offer"}
and specify the model formula as \code{offer ~ R1 | R2}.  Parameters for Player
2's reservation value are still estimable in this case, since the optimal offer
for Player 1 depends on his or her expectations of the probability of
acceptance.  Even when acceptance data are available, the option \code{outcome =
  "offer"} may be useful for making formal comparisons of the statistical
ultimatum model to OLS models of offer size, as in \citet{Ramsay2009}.  For more
on model comparison, see Section~\ref{sec:non-nest} below.

We illustrate the statistical ultimatum game with data from a classroom
experiment.  Each \code{gender} variable is an indicator for whether the
proposer (1) or receiver (2) is female.  We investigate whether players'
reservation values---the amount they get if the offer is rejected---is a
function of their gender.
<<ult2010load>>=
load("ultimatum2010.rda")
@ %
<<ult2010est,cache=true>>=
ult1 <- ultimatum(offer + accept ~ gender1 | gender2, maxOffer = 100, data =
                  ultimatum2010, s2 = 3)
@ %
<<printult1>>=
summary(ult1)
@ %
The results indicate that the female students have lower reservation values,
meaning they are more likely to make high offers (as the proposer) or accept low
ones (as the receiver).  However, neither gender coefficient is statistically
significant, so this may just be due to sampling error.


\subsection{Convergence}
\label{sec:convergence}

The log-likelihood functions for strategic models are not globally concave, so
convergence to a global maximum is not guaranteed.  We provide two methods to
avert convergence problems: well-chosen default starting values and a likelihood
profiling method.

In all of the \code{egame} models, the default starting values come from
statistical backward induction (SBI), an equation-by-equation method that uses
ordinary probit or logistic regression models to obtain consistent estimates of
the parameters \citep{Bas2007}.\footnote{SBI is based on the assumption of agent
  error, so the estimates technically are not consistent for private-information
  models.  However, for strategic models of relatively low complexity like those
  available in the \pkg{games} package, the assumption of agent error or private
  information makes little difference to the parameter estimates
  \citep{Signorino2003}.}  For example, in an \code{egame12} model with logit
link, the procedure is as follows.  Let $Y_i$ be an indicator for whether Player
$i$ chooses $R$.
\begin{enumerate}
  \item Obtain the estimate $\hat{\beta}_{24}$ by running a logistic regression
  of $Y_2$ on $X_{24}$ within the subset of observations for which $Y_1 = 1$
  (i.e., Player $2$'s choice is observed).
  \item Estimate $\hat{\beta}_{11}$, $\hat{\beta}_{13}$, and $\hat{\beta}_{14}$
  as follows:
  \begin{enumerate}
    \item Use $\hat{\beta}_{24}$ to generate predicted probabilities $\hat{p}_4$
    and $\hat{p}_3$ for Player $2$'s action.
    \item Obtain the estimates by running a logistic regression of $Y_1$ on the
    expectation-transformed data matrix $\begin{bmatrix} -X_{11} & \hat{p}_3
      X_{13} & \hat{p}_4 X_{14} \end{bmatrix}$.  The estimated coefficient
    vector is $\begin{pmatrix} \hat{\beta}_{11} & \hat{\beta}_{13} &
      \hat{\beta}_{14} \end{pmatrix}^{\top}$.
  \end{enumerate}
  \item Multiply the obtained estimates by $\sqrt{2}$ to obtain starting values
  for the full-information procedure.\footnote{This step is not necessary when
    SBI is used on its own, rather than to generate starting values.  The
    correction is for the additional dispersion induced by the agent error
    model.  Standard logit and probit methods assume a dispersion parameter of
    $1$, but Equations~\ref{eq:p4-agent} and \ref{eq:p2-agent} along with the
    assumption $\sigma = 1$ imply a dispersion parameter of $\sqrt{2}$.  The
    change makes no substantive difference for the results.}
\end{enumerate}
The applications of SBI to \code{egame122} and \code{egame123} are similar.  It
is less straightforward to generate starting values for the \code{ultimatum}
model.  We use a similar two-step procedure, but it has not been verified as
consistent and sometimes yields non-finite likelihoods, in which case starting
values of zero (except for the intercept) are used.

To assess convergence of an already-fitted model, we implement likelihood
profiling via the \code{profile.game} method.  As in the \pkg{MASS} package's
\citep{MASSpkg} \code{profile.glm} method, this entails refitting the model
numerous times, each time holding a single parameter at some value other than
the original estimate.  In the case of generalized linear models, this profiling
procedure is typically used to estimate likelihood-ratio confidence regions
\citep[254]{McCullaghNelder}.  However, it can also serve as a rough global
convergence check: if the log-likelihood of any of the refit models is greater
than that of the original fit, then by definition the original procedure did not
converge to a global maximum.  When this is the case, as in the following
example, \code{profile.game} issues a warning.
<<profiling,cache=true,results=verbatim>>=
data("student_offers")
stu1 <- ultimatum(offer + accept ~ gender1 | gender2, data = student_offers,
                  maxOffer = 100, s2 = 1)
profstu1 <- profile(stu1, which = 1:4)
@ %
% must include manually since Sweave doesn't print errors
\begin{Code}
Warning message:
In profile.game(stu1, which = 1:4) :
  some profiled fits have higher log-likelihood than original fit;
  refit the model using "profile" option
\end{Code}
The returned object, inheriting from class \code{"profile.game"}, contains the
estimates and log-likelihoods from each refitted model.  For visualization of
the profile log-likelihood, we provide the \code{plot.profile.game} method,
which displays a spline approximation.
\begin{figure}[t]
  \centering
<<plotprof,fig=true,echo=false>>=
plot(profstu1)
@ %
\caption{Output of \code{plot.profile}.}
\label{fig:plot-profile}
\end{figure}
<<eval=false,echo=true>>=
<<plotprof>>
@ %
See Figure~\ref{fig:plot-profile} for the output from this example.  Slightly lower
values of both the intercept and the gender coefficient for Player 1 appear to
yield better-fitting models.

When \code{profile.game} finds parameters that yield a higher log-likelihood
than the original fit, these can be used as starting values in re-estimation of
the model via the \code{profile} argument of the fitting function.
<<prof2,cache=true>>=
stu2 <- update(stu1, profile = profstu1)
@ %
<<printprof2>>=
logLik(stu1)
logLik(stu2)
@ %

\subsection{Reporting results}
\label{sec:report}

%% have to break up long string to keep within margins in Sweave output
<<ltable,echo=false,results=tex>>=
leb1cap <- paste("Replication of \\citeauthor{Leblang2003}'s",
                 "\\citeyearpar{Leblang2003} results.")
latexTable(leb1, caption = leb1cap,, label = "tab:leb1", floatplace = "p")
@ %

A natural form to present the results of a fitted strategic model is in a table
where each row is a covariate and each column is a utility equation.  We provide
the function \code{latexTable} to automatically generate \LaTeX\ code for such
tables.  Table~\ref{tab:leb1} was generated with the following code:
<<printltable,eval=false,echo=true>>=
<<ltable>>
@ %
Additional arguments include \code{digits} for the number of digits printed,
\code{rowsep} for the point spacing between rows, and \code{useboot} for the use
of bootstrap vs.\ normal-theory standard errors.

\section{Analyzing fitted models}
\label{sec:post}

\subsection{Predicted probabilities}
\label{sec:pred-prob}

<<pp1,cache=true,echo=false>>=
predleb1 <- predProbs(leb1, x = "lreserves", contagion = max(contagion))
@ %

\begin{figure}[t]
  \centering
<<plotpp,fig=true,echo=false>>=
par(mfrow=c(2, 2))
plot(predleb1)
@ %
\caption{Output of \code{plot.predProbs}.}
\label{fig:plot-pp}
\end{figure}

The raw output from the model fitting functions in \pkg{games} describes the
effect of each covariate on players' utilities for different outcomes.  Some
analysts may instead be interested in how each variable affects the probability
of a particular outcome occurring.  Such probabilities are nonlinear functions
of the covariates; for example, they are given by Equations~\ref{eq:p4-agent}
and \ref{eq:p2-agent} for \code{egame12} models with agent error.  Following
popular developments in the political science literature \citep{King2000}, we
provide the function \code{predProbs} to analyze how the predicted probability
of each outcome changes as a function of certain covariates.  The general
procedure is:
\begin{enumerate}
  \item Select a ``covariate of interest,'' $X_j$.
  \item Hold all other variables at their central values --- means for
  continuous variables, medians for binary or ordinal variables, modes for
  others --- or some other pre-specified ``profile'' $X_{-j} = (X_{j'})_{j' \neq
    j}$.
  \item Using the estimated model, find the predicted probability of each
  potential outcome over the observed range of $X_j$, while holding $X_{-j}$
  fixed.
  \item Calculate confidence intervals for the predicted values using a
  parametric or nonparametric bootstrap.
  \item Plot the results.
\end{enumerate}
The only mandatory arguments for \code{predProbs} are \code{model}, for the
fitted model object, and \code{x}, a character string containing the name of the
variable of interest (partial matches are allowed).  If \code{x} is numeric,
then the default behavior is to evaluate predicted probabilities at $100$ grid
points along the range observed for \code{x} in the data used to fit the model
(i.e., the data frame \code{model\$model}).  The number of grid points and range
of values can be controlled via the arguments \code{n} and \code{xlim}
respectively.  If \code{x} is a factor variable, all available levels are used.

Additional named arguments can be used to change the default profile of values
for the covariates other than \code{x}.  These arguments should be specified as
\code{varname = value}, where \code{varname} exactly matches the name of the
variable in the data frame used to fit the model and \code{value} is an
expression that is evaluated within the model frame, \code{model\$model}.  For
example, to set a variable \code{y} to its observed 10th percentile, use the
argument \code{y = quantile(y, probs = 0.1)}.

\sloppy
Confidence intervals for the predictions are calculated by resampling.  If
\code{model} has a \code{boot.matrix} element containing nonparametric bootstrap
results, these are used.  Otherwise, a matrix of parametric bootstrap results is
constructed by taking 1,000 samples from a multivariate normal distribution
whose mean is $\hat{\beta}$ and whose variance matrix is the inverse of the
negative Hessian of the estimates.  The default is to compute a 95\% confidence
interval; this can be controlled by the \code{ci} argument.  It normally takes a
few seconds to compute the fitted values for all of the bootstrapped
coefficients, so a status bar is displayed.  This can be suppressed by setting
\code{report = FALSE}.

\fussy
We illustrate with an example from Leblang's data.  Suppose we are interested in
the estimated effect of currency reserves on the outcome probabilities when
contagion is high (currency attacks are occurring elsewhere) but all other
variables are held at their central values.  We would use \code{predProbs} as
follows.
<<echo=true,eval=false>>=
<<pp1>>
@ %
% doing this manually b/c no printing from cached blocks
\begin{Code}
Calculating confidence intervals...
========================================================================
\end{Code}
The return value is an object inheriting from classes \code{"predProbs"} and
\code{"data.frame"}.  This is a data frame with \code{n} (or \code{nlevels(x)},
if \code{x} is a factor) rows, each containing a profile, the predicted
probabilities for each outcome, and the confidence bands on each predicted
probability.

The method \code{plot.predProbs} can be used for visualization of the output.
The number of plots that can be produced from \code{predProbs} output is equal
to the number of outcomes in the corresponding fitted model (e.g., three for an
\code{egame12} model).  To deal with this, we have written \code{plot.predProbs}
to behave similarly to \code{plot.gam} in the \pkg{gam} package \citep{gampkg},
in which each fitted model corresponds to as many plots as there are covariates.
<<echo=true,eval=false>>=
<<plotpp>>
@ %
See Figure~\ref{fig:plot-pp} for the output.  If no additional arguments are
specified to \code{plot.predProbs(x)}, all of the plots are printed in sequence.
If \code{ask = TRUE} is specified, then an interactive menu is used for plot
selection:
\begin{Code}
R> plot(predleb1, ask = TRUE)
Make a plot selection (or 0 to exit):

1: plot: Pr(no attack)
2: plot: Pr(devaluation)
3: plot: Pr(defense)
4: plot all terms
\end{Code}
The argument \code{which} can be used to select one of these without bringing up
the menu; e.g., \code{plot(predleb1, which = 2)} will produce only the plot for
the devaluation outcome.  In each case, all of the standard plotting arguments
can be used to control the output.  To change the line type used for the
confidence bands, use the argument \code{lty.ci}.

\subsection{Non-nested model comparisons}
\label{sec:non-nest}

It is not possible to express traditional discrete-choice models like logistic
regression as ``restricted'' strategic models, or vice versa.  Therefore,
standard likelihood ratio tests are inappropriate for comparing the fit of a
strategic model to that of a generalized linear model; a non-nested model
comparison is necessary \citep{Clarke2010}.  The \pkg{games} package implements
the tests of \citet{Vuong1989} and \citet{Clarke2006} via the \code{vuong} and
\code{clarke} functions respectively.  Each test compares two models, under the
null hypothesis that the two have an equal Kullback-Leibler distance from the
true model.  Both use test statistics formed from the log-likelihood
contributions of each individual observation.  The main difference is that
Clarke's test is unbiased in finite samples, whereas Vuong's depends on
asymptotic properties.  We implement both tests with the recommended BIC-based
correction to penalize overparameterization.

The simplest use of the non-nested test functions is to compare two strategic
models to each other.  For example, we can use them to determine whether agent
error or private information is more appropriate for Leblang's data.
<<lebagent,cache=true>>=
lebagent <- update(leb1, type = "agent", boot = 0)
@ %
<<lebtest>>=
vuong(leb1, lebagent)
@ %
Neither stochastic structure appears to be significantly preferred over the
other.

It is somewhat less straightforward to compare strategic to non-strategic
models.  Vuong's and Clarke's tests can be applied only to pairs of models for
which the dependent variable is exactly the same.  In a strategic model lik
\code{egame12}, the dependent variable for each observation is the outcome
reached---i.e., the vector of all decisions made by each player.  By contrast,
in a standard (binary) logistic regression model, the dependent variable is an
indicator for whether one particular outcome was reached.  To allow for
comparisons in such cases, the \code{vuong} and \code{clarke} functions have
\code{outcome} arguments.  For example, we could compare the strategic model of
Leblang's data to a logistic regression in terms of their ability to predict the
occurrence of speculative attacks as follows.
<<leblogit,cache=true>>=
leblang2003$noattack <- 1 - leblang2003$attack
logit1 <- glm(noattack ~ lreserves + overval + creditgrow + contagion + prioratt
              + rightgov + realinterest, data = leblang2003, family = binomial)
@ %
<<lebvslogit>>=
vuong(model1 = leb1, outcome1 = 1, model2 = logit1)
@ %
The logistic regression is preferred despite having a lower log-likelihood,
since it fits 8 parameters compared to the strategic model's 19.  The argument
\code{outcome1 = 1} is used to indicate that the strategic model should be
evaluated in terms of its fit with the market's decision not to initiate a
currency attack.  We would have used \code{outcome1 = 2} to consider the outcome
of a speculative attack followed by devaluation, and \code{outcome1 = 3} for an
attack followed by defense.  Of course, these could not have been compared to
\code{logit1}, and \code{vuong} or \code{clarke} would stop with an error after
detecting models with different dependent variables.

\section{Conclusion}

We have provided new software, the \pkg{games} package, for estimation of
strategic statistical models in \proglang{R}.  We argue that such models are
appropriate for the analysis of data where agents' expectations of each other's
actions determine their choices.  The new software implements multiple strategic
models, including a statistical bargaining game.  The software is easy to use
and includes post-estimation features such as non-nested comparison tests and
plots of fitted values with measures of uncertainty.  We show that the software
can be used to easily replicate one well-known analysis of a strategic
statistical model \citep{Leblang2003}.


\section*{Acknowledgments}

We are grateful to David Leblang for sharing his data.  We thank the Wallis
Institute for Political Economy at the University of Rochester for financial
support.


\bibliography{games,software}

\end{document}
